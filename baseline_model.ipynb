{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_file,label_file):\n",
    "    \n",
    "    with open(data_file) as f:\n",
    "        data = f.read().split('\\n')\n",
    "        \n",
    "    with open(label_file) as f:\n",
    "        labels = f.read().split('\\n')\n",
    "        \n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat,lab = read_data('baseline_hits.txt','baseline_hits_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline and model building:\n",
    "\n",
    "TF = TfidfVectorizer()\n",
    "X = TF.fit_transform(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 96 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 316 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=['i', 'me',\n",
       "                                                                    'my'...\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'logreg__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
       "                         'tfidf__lowercase': [True, False],\n",
       "                         'tfidf__max_df': [0.9, 0.95, 0.98, 1.0],\n",
       "                         'tfidf__min_df': [1, 2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(dat,lab,test_size=0.2,random_state=42)\n",
    "\n",
    "# Stopwords in english\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop)),\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "#pipe.fit(X_train,y_train)\n",
    "params = {\"tfidf__lowercase\":[True,False],\n",
    "          \"tfidf__max_df\":[0.9,0.95,0.98,1.0],\n",
    "          \"tfidf__min_df\":[1,2],\n",
    "          \"logreg__C\":[0.001,0.01,0.1,1.0,10.0,100.0]}\n",
    "\n",
    "searchLR = GridSearchCV(pipe,param_grid=params,n_jobs=-1,verbose=3,scoring='roc_auc',cv=4)\n",
    "\n",
    "searchLR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 10.0,\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__min_df': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchLR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchLR.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "1. Take a look at the accuracy/precision for both the 0 and the 1 class\n",
    "2. Try a Naive Bayes classifier\n",
    "3. Try more text preprocessing than simply lower-case. We can make a function and use it in the pipeline as a tf-idf parameter (look into the \"preprocessor\" parameter: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "4. run best-performing model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best version of LR based on GridSearch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_best = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    binary=False,\n",
    "    decode_error='strict',\n",
    "    encoding='utf-8',\n",
    "    input='content',\n",
    "    lowercase=True,\n",
    "    max_df=0.9,\n",
    "    max_features=None,\n",
    "    min_df=2,\n",
    "    ngram_range=(1, 1),\n",
    "    norm='l2',\n",
    "    preprocessor=None,\n",
    "    smooth_idf=True,\n",
    "    stop_words= stop)\n",
    "X_best = TF_best.fit_transform(dat)\n",
    "\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best,lab,test_size=0.2,random_state=42)\n",
    "\n",
    "LR_best = LogisticRegression(C=10)\n",
    "LR_best.fit(X_train_best, y_train_best)\n",
    "\n",
    "LR_best.score(X_test_best, y_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0\n",
      "Precision: nan\n",
      "Accuracy: 0.55\n",
      "F1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan/Documents/Code/python-environments/SI699/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_best, LR_best.predict(X_test_best)).ravel()\n",
    "\n",
    "recall_best = tp/(tp+fn)\n",
    "precision_best = tp/(tp+fp)\n",
    "accuracy_best = (tp+tn)/(tp+tn+fp+fn)\n",
    "f1_best = 2*((precision_best+recall_best)/(precision_best+recall_best))\n",
    "\n",
    "print(f\"Recall: {recall_best}\\nPrecision: {precision_best}\\nAccuracy: {accuracy_best}\\nF1: {f1_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 160 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop)),\n",
    "    ('NB', MultinomialNB(alpha=0.001))\n",
    "])\n",
    "\n",
    "#pipe.fit(X_train,y_train)\n",
    "params = {\"tfidf__lowercase\":[True,False],\n",
    "          \"tfidf__max_df\":[0.9,0.95,0.98,1.0],\n",
    "          \"tfidf__min_df\":[1,2],\n",
    "          \"NB__alpha\": [0,0.0001,0.001,0.01,1],\n",
    "          \"NB__fit_prior\": [True,False],\n",
    "         }\n",
    "\n",
    "searchNB = GridSearchCV(pipe,param_grid=params,n_jobs=-1,verbose=3,scoring='roc_auc',cv=4)\n",
    "\n",
    "searchNB.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NB__alpha': 0.0001,\n",
       " 'NB__fit_prior': True,\n",
       " 'tfidf__lowercase': True,\n",
       " 'tfidf__max_df': 0.9,\n",
       " 'tfidf__min_df': 2}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchNB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56640625"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchNB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.9, max_features=None,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('NB',\n",
       "                 MultinomialNB(alpha=0.0001, class_prior=None,\n",
       "                               fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchNB.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best version of NB based on GridSearch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_best = TfidfVectorizer(\n",
    "    analyzer='word', binary=False,\n",
    "    decode_error='strict',\n",
    "    encoding='utf-8', input='content',\n",
    "    lowercase=True, max_df=0.9, max_features=None,\n",
    "    min_df=2, ngram_range=(1, 1), norm='l2',\n",
    "    preprocessor=None, smooth_idf=True,\n",
    "    stop_words=stop,\n",
    "    strip_accents=None, sublinear_tf=False,\n",
    "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    tokenizer=None, use_idf=True,\n",
    "    vocabulary=None\n",
    ")\n",
    "X_best = TF_best.fit_transform(dat)\n",
    "\n",
    "X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best,lab,test_size=0.2,random_state=42)\n",
    "\n",
    "NB_best = MultinomialNB(\n",
    "    alpha=0.0001, \n",
    "    class_prior=None, \n",
    "    fit_prior=True\n",
    ")\n",
    "\n",
    "NB_best.fit(X_train_best, y_train_best)\n",
    "\n",
    "NB_best.score(X_test_best, y_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "Accuracy: 0.5\n",
      "F1: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan/Documents/Code/python-environments/SI699/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test_best, NB_best.predict(X_test_best)).ravel()\n",
    "\n",
    "recall_best = tp/(tp+fn)\n",
    "precision_best = tp/(tp+fp)\n",
    "accuracy_best = (tp+tn)/(tp+tn+fp+fn)\n",
    "f1_best = 2*((precision_best+recall_best)/(precision_best+recall_best))\n",
    "\n",
    "print(f\"Recall: {recall_best}\\nPrecision: {precision_best}\\nAccuracy: {accuracy_best}\\nF1: {f1_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "np.random.choice(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
