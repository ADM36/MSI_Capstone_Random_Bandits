{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this NB is to assess the interannotator agreement for results provided by annotators. Since we expect to have multiple annotators we'll use Fleiss' kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Fleiss' kappa = \"It can be interpreted as expressing the extent to which the observed amount of agreement among raters exceeds what would be expected if all raters made their ratings completely randomly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://www.wikiwand.com/en/Fleiss%27_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.metrics.agreement import AnnotationTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:magenta\"> Enter the name of the results file below </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE = \"test.csv\" #enter the name of a given results file\n",
    "\n",
    "infile = pd.read_csv('./data/annotation_results/'+RESULTS_FILE, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotator_Aaron       0\n",
       "Annotator_Andrew      0\n",
       "Annotator_Bryan       0\n",
       "Annotator_Aaron.1     0\n",
       "Annotator_Andrew.1    0\n",
       "Annotator_Bryan.1     0\n",
       "Text                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile.isna().sum() #check if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_sub = infile.loc[:, infile.columns.str.startswith('Annotat')]\n",
    "# infile_sub = infile.loc[:,['Annotator_Bryan', 'Annotator_Aaron', 'Annotator_Andrew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan/Documents/Code/python-environments/SI699/lib/python3.6/site-packages/pandas/core/generic.py:7496: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._clip_with_scalar(lower, upper, inplace=inplace)\n"
     ]
    }
   ],
   "source": [
    "infile_sub.clip(lower=0, upper=1, inplace=True) #for our current purposes, don't need counts over 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to 3-tuples of (<coder>, <item>, <label>)\n",
    "infile_tuples = [(col, index, infile_sub[col].iloc[index]) for col in infile_sub.columns for index in infile_sub.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Fleiss kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss kappa for all annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Fleiss kappa: 0.714\n"
     ]
    }
   ],
   "source": [
    "assess_infile = AnnotationTask(data = infile_tuples)\n",
    "print(f\"Overall Fleiss kappa: {round(assess_infile.multi_kappa(),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss kappa for groups of annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us = infile_sub[['Annotator_Bryan', 'Annotator_Aaron', 'Annotator_Andrew']]\n",
    "# them = infile_sub[['Annotator_Mom', 'Annotator_Kelly', 'Annotator_Abigail']]\n",
    "\n",
    "# them_tuples = [(col, index, them[col].iloc[index]) for col in them.columns for index in them.index]\n",
    "# us_tuples = [(col, index, us[col].iloc[index]) for col in us.columns for index in us.index]\n",
    "\n",
    "# assess_them = AnnotationTask(data = them_tuples)\n",
    "# print(f\"Their kappa: {round(assess_them.multi_kappa(),3)}\")\n",
    "\n",
    "# assess_us = AnnotationTask(data = us_tuples)\n",
    "# print(f\"Our kappa: {round(assess_us.multi_kappa(),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts of all annotators agreeing, half or more annotators agreeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_ANNOTATORS: 6\n",
      "HALF_POSITIVE: 3\n"
     ]
    }
   ],
   "source": [
    "NUM_ANNOTATORS = len(infile_sub.columns)\n",
    "\n",
    "HALF_POSITIVE = round(NUM_ANNOTATORS/2)\n",
    "\n",
    "print(f\"NUM_ANNOTATORS: {NUM_ANNOTATORS}\\nHALF_POSITIVE: {HALF_POSITIVE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_agree = infile[(infile.sum(axis=1) == NUM_ANNOTATORS)|(infile.sum(axis=1) == 0)]\n",
    "\n",
    "len(all_agree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_plus_agree = infile[(infile.sum(axis=1) >= HALF_POSITIVE)&(infile.sum(axis=1) < NUM_ANNOTATORS)]\n",
    "\n",
    "len(half_plus_agree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts where a label = one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator_Aaron| Positive label count: 12\n",
      "Annotator_Andrew| Positive label count: 9\n",
      "Annotator_Bryan| Positive label count: 11\n",
      "Annotator_Aaron.1| Positive label count: 12\n",
      "Annotator_Andrew.1| Positive label count: 9\n",
      "Annotator_Bryan.1| Positive label count: 11\n"
     ]
    }
   ],
   "source": [
    "annotators = list(infile.columns[infile.columns.str.startswith(\"Annotat\")])\n",
    "for annotator in annotators:\n",
    "    print(f\"{annotator}| Positive label count: {infile[annotator].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaners: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Text, dtype: object)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaners = infile[(infile.sum(axis=1) == 1)|(infile.sum(axis=1) == (NUM_ANNOTATORS-1))] #count of where only one annotator assigned a one\n",
    "\n",
    "print(f\"Number of loaners: {len(loaners)}\")\n",
    "loaners.Text if \"Text\" in loaners.columns else print(\"No text provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number where half or fewer annotators assigned positive labels: 7\n"
     ]
    }
   ],
   "source": [
    "half_fewer_ones = infile[(infile.sum(axis = 1) <= HALF_POSITIVE)&(infile.sum(axis = 1) > 0)] #count of where half of annotators assigned a one\n",
    "\n",
    "print(f\"Number where half or fewer annotators assigned positive labels: {len(half_fewer_ones.index)}\")\n",
    "# half_ones.Text if \"Text\" in half_ones.columns else print(\"No text provided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number where more than half of all annotators assigned positive labels: 2\n"
     ]
    }
   ],
   "source": [
    "half_plus_ones = infile[(infile.sum(axis = 1) > HALF_POSITIVE)&(infile.sum(axis = 1) < NUM_ANNOTATORS)] #count of where more than half of annotators assigned a one\n",
    "\n",
    "print(f\"Number where more than half of all annotators assigned positive labels: {len(half_plus_ones.index)}\")\n",
    "# half_plus_ones.Text if \"Text\" in half_plus_ones.columns else print(\"No text provided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of any annotator awarding a one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(infile[infile.sum(axis=1) >= 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results for \"us vs. them\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us[\"sum\"] = us.sum(axis = 1)\n",
    "# them[\"sum\"] = them.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_them = pd.merge(us, them, left_index = True, right_index = True, suffixes = (\"_us\", \"_them\"))\n",
    "# us_them[\"abs_diff\"] = abs(us_them[\"sum_us\"]-us_them[\"sum_them\"])\n",
    "\n",
    "# signif_indices = list(us_them[us_them[\"abs_diff\"]!=0].index) #list of indices with signif disagreement between us & them\n",
    "\n",
    "# infile.iloc[signif_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculation of Fleiss kappa\n",
    "> ### Intended as a verification of the calculation of multi_kappa() above. Based off: https://www.wikiwand.com/en/Fleiss%27_kappa#/Worked_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels = [infile[col].iloc[index] for col in infile.columns for index in infile.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_var = len(infile.columns) #number of raters\n",
    "# N_var = infile.shape[0] #number of observations/records\n",
    "# k_var = len(set(all_labels)) #number of categories/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate P_j\n",
    "# P_j1 = (1/(N_var*n_var))*sum(infile.sum(axis=1))\n",
    "# P_j0 = (1/(N_var*n_var))*sum(n_var - infile.sum(axis=1))\n",
    "\n",
    "# # P_j0, P_j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate P_i\n",
    "\n",
    "# P_i = 1/(n_var*(n_var-1))*(((infile.sum(axis=1)**2)+((n_var - infile.sum(axis=1))**2))-n_var)\n",
    "\n",
    "# # P_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculate P_bar\n",
    "# P_bar = (1/N_var)*sum(P_i)\n",
    "\n",
    "# # P_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #caculate P_bar_e\n",
    "\n",
    "# P_bar_e = (P_j0**2)+(P_j1**2)\n",
    "\n",
    "# # P_bar_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fleiss_kappa = (P_bar - P_bar_e)/(1-P_bar_e)\n",
    "\n",
    "# fleiss_kappa #close-ish to the multi_kappa() calculation above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate agreement across multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/mturk_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for root, dirs, files in os.walk(PATH):\n",
    "    filenames.append(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files = filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_results = []\n",
    "for i in filtered_files:\n",
    "    infile = pd.read_csv(PATH+i, index_col=0)\n",
    "    infile[\"checker\"] = infile.apply(lambda x: 1 if x[\"Answer.yes.1\"]==x[\"Answer.no.0\"] else 0, axis= 1)\n",
    "    subset_infile = infile[infile[\"checker\"]==0]\n",
    "    \n",
    "    find = subset_infile.groupby(\"HITId\").mean()[[\"Answer.yes.1\",\"Answer.no.0\"]]\n",
    "    find[\"agree\"] = find.apply(lambda x: max(x), axis=1)\n",
    "    agreement = find[\"agree\"].mean()\n",
    "    \n",
    "    these_results.append((i,round(agreement,3)))\n",
    "    \n",
    "#     print(i, round(agreement,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Proportion of agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will_mturk_results_3_filtered.csv</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get_mturk_results_1_filtered.csv</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get_mturk_results_3_filtered.csv</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will_mturk_results_5_filtered.csv</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go_mturk_results_1_filtered.csv</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get_mturk_results_2_filtered.csv</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos_mturk_results_2_filtered.csv</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>will_mturk_results_1_filtered.csv</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>go_mturk_results_2_filtered.csv</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>go_mturk_results_4_filtered.csv</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>will_mturk_results_4_filtered.csv</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>go_mturk_results_3_filtered.csv</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pos_mturk_results_3_filtered.csv</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>POS_mturk_results_4_filtered.csv</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File  Proportion of agreement\n",
       "0   will_mturk_results_3_filtered.csv                    0.857\n",
       "1    get_mturk_results_1_filtered.csv                    0.844\n",
       "2    get_mturk_results_3_filtered.csv                    0.783\n",
       "3   will_mturk_results_5_filtered.csv                    0.843\n",
       "4     go_mturk_results_1_filtered.csv                    0.899\n",
       "5    get_mturk_results_2_filtered.csv                    0.955\n",
       "6    pos_mturk_results_2_filtered.csv                    0.933\n",
       "7   will_mturk_results_1_filtered.csv                    0.847\n",
       "8     go_mturk_results_2_filtered.csv                    0.795\n",
       "9     go_mturk_results_4_filtered.csv                    0.827\n",
       "10  will_mturk_results_4_filtered.csv                    0.773\n",
       "11    go_mturk_results_3_filtered.csv                    0.770\n",
       "12   pos_mturk_results_3_filtered.csv                    0.913\n",
       "13   POS_mturk_results_4_filtered.csv                    0.849"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agree_df = pd.DataFrame(these_results, columns = [\"File\",\"Proportion of agreement\"])\n",
    "agree_df #average agreement is 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = pd.read_csv(PATH+filtered_files[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "this[\"checker\"] = this.apply(lambda x: 1 if x[\"Answer.yes.1\"]==x[\"Answer.no.0\"] else 0, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_subset = this[this[\"checker\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair = this_subset.groupby(\"HITId\").mean()[[\"Answer.yes.1\",\"Answer.no.0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "chair[\"agree\"] = chair.apply(lambda x: max(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566666666666666"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chair[\"agree\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = this[[\"HITId\",\"WorkerId\"]].groupby('HITId').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in check[\"WorkerId\"].unique():\n",
    "#     if i > 1:\n",
    "#         these_HITs = list(check[check[\"WorkerId\"]==i].index)\n",
    "#         print(\"*\"*8) \n",
    "        \n",
    "#         #subset larger df based on these_HITs\n",
    "#         this_subset = this[this[\"HITId\"].isin(these_HITs)]\n",
    "        \n",
    "#         these_tuples = [x for x in this_subset[[\"WorkerId\",\"HITId\",\"Answer.yes.1\"]].to_records(index=False)] # (annotator_ID, item_ID, label)\n",
    "#         assess_infile = AnnotationTask(data = these_tuples)\n",
    "#         print(f\"Overall Fleiss kappa: {round(assess_infile.multi_kappa(),3)}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in filtered_files:\n",
    "#     infile = pd.read_csv(PATH+i, index_col=0)\n",
    "#     infile[\"Answer.yes.1\"] = [1 if x else 0 for x in infile[\"Answer.yes.1\"]]\n",
    "    \n",
    "#     # get subsets\n",
    "    \n",
    "#     ## get tuples & calculate kappa\n",
    "    \n",
    "    \n",
    "#     these_tuples = [x for x in infile[[\"WorkerId\",\"HITId\",\"Answer.yes.1\"]].to_records(index=False)] # (annotator_ID, item_ID, label)\n",
    "#     assess_infile = AnnotationTask(data = these_tuples)\n",
    "#     print(f\"{i} - Overall Fleiss kappa: {round(assess_infile.multi_kappa(),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in filtered_files:\n",
    "#     infile = pd.read_csv(PATH+i, index_col=0)\n",
    "#     infile[\"checker\"] = infile.apply(lambda x: 1 if x[\"Answer.yes.1\"]==x[\"Answer.no.0\"] else 0, axis= 1)\n",
    "    \n",
    "#     print(i,\"-\", infile[infile[\"checker\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
